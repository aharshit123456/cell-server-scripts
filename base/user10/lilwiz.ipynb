{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pandas scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Maintenance of Nuclear Reactors\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we will develop a machine learning model to predict potential failures in nuclear reactors by analyzing sensor data from the AI4I 2020 Predictive Maintenance Dataset. This predictive maintenance approach can help in timely maintenance and prevent catastrophic failures.\n",
    "\n",
    "### Objectives\n",
    "- Data Collection and Preprocessing\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- Model Selection and Training\n",
    "- Model Evaluation\n",
    "- Conclusion and Future Work\n",
    "\n",
    "### Evaluation Parameters\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-Score\n",
    "- ROC-AUC\n",
    "\n",
    "### Scoring Method\n",
    "Each model will be scored based on the weighted average of the above metrics, with specific weights assigned based on the hackathon criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## Data Collection\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00601/ai4i2020.csv'\n",
    "df = pd.read_csv(data_url)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## Data Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Handle missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Encode categorical variables if any\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df.drop('Machine failure', axis=1))\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, df['Machine failure'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## Exploratory Data Analysis (EDA)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualizing sensor data\n",
    "sns.pairplot(df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identifying patterns and anomalies\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Model Selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Instantiate the models\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "svc_model = SVC(random_state=42, probability=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Model Training\n",
    "# Train the Random Forest model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Train the SVM model\n",
    "svc_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Model Evaluation\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    probas = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    roc_auc = roc_auc_score(y_test, probas) if probas is not None else None\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    if roc_auc:\n",
    "        print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    return accuracy, precision, recall, f1, roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate Random Forest model\n",
    "print(\"Random Forest Model Performance:\")\n",
    "rf_metrics = evaluate_model(rf_model, X_test, y_test)\n",
    "\n",
    "# Evaluate SVM model\n",
    "print(\"\\nSVM Model Performance:\")\n",
    "svc_metrics = evaluate_model(svc_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate SVM model\n",
    "print(\"\\nSVM Model Performance:\")\n",
    "svc_metrics = evaluate_model(svc_model, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
