{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Chronic Disease Outcomes Using Electronic Health Records (EHRs)\n",
    "\n",
    "## Objective\n",
    "Develop a model to predict the outcomes of chronic diseases based on patient electronic health records.\n",
    "\n",
    "## Dataset\n",
    "[Public Health Data from the UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Heart+Disease) - This dataset includes various health indicators and outcomes for patients with chronic conditions.\n",
    "\n",
    "## Problem Statement\n",
    "Build a model to predict the long-term outcomes for patients with chronic diseases like heart disease or hypertension, helping clinicians make informed decisions about patient management.\n",
    "\n",
    "## Evaluation Metrics\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data'\n",
    "column_names = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"]\n",
    "df = pd.read_csv(data_url, names=column_names, na_values=\"?\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Handle missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualizing target distribution\n",
    "sns.countplot(x='target', data=df)\n",
    "plt.title('Target Variable Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Identifying patterns and anomalies\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "# Instantiate the models\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "svc_model = SVC(random_state=42, probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "# Train the Random Forest model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Train the SVM model\n",
    "svc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Evaluate Random Forest model\n",
    "print(\"Random Forest Model Performance:\")\n",
    "rf_metrics = evaluate_model(rf_model, X_test, y_test)\n",
    "\n",
    "# Evaluate SVM model\n",
    "print(\"\\nSVM Model Performance:\")\n",
    "svc_metrics = evaluate_model(svc_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we developed and evaluated machine learning models for predicting the outcomes of chronic diseases using electronic health records from the UCI Heart Disease dataset. The models were trained on patient data and evaluated for their performance in predicting long-term outcomes.\n",
    "\n",
    "### Summary of Findings\n",
    "- Random Forest and SVM models were trained and evaluated.\n",
    "- Key evaluation metrics were considered: Precision, Recall, and F1 Score.\n",
    "\n",
    "### Future Work\n",
    "- Collect more diverse and extensive datasets.\n",
    "- Experiment with more advanced machine learning models.\n",
    "- Integrate real-time data analysis for continuous monitoring."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
